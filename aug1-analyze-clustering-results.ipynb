{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiatoolbox-simple environment\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from source.constants import ORIGINAL_2_PRETTY_MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_original_patches = 50\n",
    "num_augs = 10\n",
    "num_patches = num_original_patches * num_augs\n",
    "num_connections = num_patches * (num_patches - 1) // 2\n",
    "\n",
    "# dataset = 'TCIA-CPTAC'\n",
    "lung_datasets = [\n",
    "    'TCIA-CPTAC',\n",
    "    'TCGA-lung',\n",
    "    'ouh_batch1_20x', 'ouh_batch1_40x', 'ouh_batch2_20x', 'ouh_batch3_40x',\n",
    "    'DART_001', 'DART_002', 'DART_003', 'DART_004',\n",
    "    # 'DHMC_20x', 'DHMC_40x',\n",
    "]\n",
    "all_datasets = lung_datasets + ['CAMELYON16']\n",
    "\n",
    "original_2_shorter_metric_names = {\n",
    "    'Adjusted Rand Index (ARI)': 'Adjusted Rand Index',\n",
    "    'Normalized Mutual Information (NMI)': 'Normalized Mutual Info',\n",
    "}\n",
    "OPTIMIZING_METRIC = 'Fowlkes-Mallows Index'\n",
    "\n",
    "model_2_color = {\n",
    "    'Phikon-v2': 'orange',\n",
    "    'Prov-GigaPath': 'blue',\n",
    "    'ResNet18-SimCLR': 'black',\n",
    "    'ResNet18-camelyon16-20x': 'black',\n",
    "    'ResNet18-lung-10x': 'black',\n",
    "    'UNI': 'red',\n",
    "    'Virchow-v1-Concat': 'yellow',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_df(dataset: str):\n",
    "    eval_csv_path = f'eval_results/dataset={dataset}#extractor_name=all#img_norm=all#distance_metric=cosine#dimensionality_reduction=none#clustering=kmeans.csv'\n",
    "    eval_df = pd.read_csv(eval_csv_path)\n",
    "    \n",
    "    # initial transformations\n",
    "    eval_df['dataset'] = dataset\n",
    "    eval_df = eval_df.rename(columns={eval_df.columns[0]: 'model#img_norm#wsi_id'})\n",
    "    eval_df.rename(columns=original_2_shorter_metric_names, inplace=True)\n",
    "\n",
    "    # info columns\n",
    "    eval_df['model'] = eval_df['model#img_norm#wsi_id'].apply(lambda x: x.split('#')[0])\n",
    "    eval_df['model'] = eval_df['model'].apply(lambda x: ORIGINAL_2_PRETTY_MODEL_NAMES[x])\n",
    "    eval_df['img_norm'] = eval_df['model#img_norm#wsi_id'].apply(lambda x: x.split('#')[1])\n",
    "    eval_df['wsi_id'] = eval_df['model#img_norm#wsi_id'].apply(lambda x: x.split('#')[2])\n",
    "    eval_df.drop(columns=['model#img_norm#wsi_id'], inplace=True)\n",
    "    info_columns = ['model', 'img_norm', 'wsi_id', 'dataset']\n",
    "\n",
    "    # drop ResNet18-imagenet combination\n",
    "    remove_condition = (eval_df['model'].str.startswith('ResNet18')) & (eval_df['img_norm'] == 'imagenet')\n",
    "    eval_df = eval_df[~remove_condition]\n",
    "    \n",
    "    # confusion matrix columns\n",
    "    conf_matrix_columns = ['TP', 'FP', 'FN', 'TN']\n",
    "    eval_df['total_connections'] = eval_df[conf_matrix_columns].sum(axis=1)\n",
    "    conf_matrix_columns.append('total_connections')\n",
    "\n",
    "    # metric columns\n",
    "    \n",
    "    metric_columns = [\n",
    "        col for col in eval_df.columns\n",
    "        if col not in set(info_columns).union(set(conf_matrix_columns))\n",
    "    ]\n",
    "    \n",
    "    # metric_columns_wo_precision\n",
    "    metric_columns_wo_precision = [\n",
    "        col for col in metric_columns\n",
    "        if 'precision' not in col\n",
    "    ]\n",
    "\n",
    "    # reorder\n",
    "    eval_df = eval_df[info_columns + conf_matrix_columns + metric_columns]\n",
    "\n",
    "    return {\n",
    "        'df':eval_df,\n",
    "        'info_columns':info_columns,\n",
    "        'conf_matrix_columns':conf_matrix_columns,\n",
    "        'metric_columns':metric_columns,\n",
    "        'metric_columns_wo_precision':metric_columns_wo_precision,\n",
    "    }\n",
    "\n",
    "def get_eval_df_from_list(datasets: list[str]):\n",
    "    eval_dfs = [get_eval_df(dataset) for dataset in datasets]\n",
    "    result = {\n",
    "        'df': pd.concat([eval_df['df'] for eval_df in eval_dfs]),\n",
    "        'info_columns': eval_dfs[0]['info_columns'],\n",
    "        'conf_matrix_columns': eval_dfs[0]['conf_matrix_columns'],\n",
    "        'metric_columns': eval_dfs[0]['metric_columns'],\n",
    "        'metric_columns_wo_precision': eval_dfs[0]['metric_columns_wo_precision'],\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def get_full_slides_condition(eval_df: pd.DataFrame):\n",
    "    full_slides_condition = (eval_df['total_connections'] == num_connections)\n",
    "    return full_slides_condition\n",
    "\n",
    "def get_agg_df(eval_df: pd.DataFrame, condition: pd.Series, agg: str):\n",
    "    return eval_df[condition].drop(columns=['wsi_id', 'dataset']).groupby(['model', 'img_norm']).agg(agg).sort_values('model').reset_index()\n",
    "\n",
    "def get_agg_df_per_dataset(eval_df: pd.DataFrame, condition: pd.Series, agg: str):\n",
    "    return eval_df[condition].drop(columns=['wsi_id']).groupby(['model', 'img_norm', 'dataset']).agg(agg).sort_values('model').reset_index()\n",
    "\n",
    "\n",
    "def get_mean_and_std_dfs(dataset: str):\n",
    "    eval_df = get_eval_df(dataset)['df']\n",
    "    full_slides_condition = get_full_slides_condition(eval_df)\n",
    "    mean_agg_df = get_agg_df(eval_df, full_slides_condition, 'mean')\n",
    "    std_agg_df = get_agg_df(eval_df, full_slides_condition, 'std')\n",
    "    return mean_agg_df, std_agg_df\n",
    "\n",
    "# for dataset in all_datasets:\n",
    "#     mean_agg_df, std_agg_df = get_mean_and_std_dfs(dataset)\n",
    "#     display(mean_agg_df)\n",
    "#     display(std_agg_df)\n",
    "#     print('='*80)\n",
    "\n",
    "def get_mean_and_std_dfs_from_list(datasets_list: list[str]):\n",
    "    print(datasets_list)\n",
    "    eval_dfs = [get_eval_df(dataset)['df'] for dataset in datasets_list]\n",
    "    combined_eval_df = pd.concat(eval_dfs)\n",
    "    full_slides_condition = get_full_slides_condition(combined_eval_df)\n",
    "    print(f\"full_slides_condition.mean() {full_slides_condition.mean()}\")\n",
    "    mean_agg_df = get_agg_df(combined_eval_df, full_slides_condition, 'mean')\n",
    "    std_agg_df = get_agg_df(combined_eval_df, full_slides_condition, 'std')\n",
    "    return mean_agg_df, std_agg_df\n",
    "\n",
    "def get_mean_and_std_dfs_per_dataset_from_list(datasets_list: list[str]):\n",
    "    print(datasets_list)\n",
    "    eval_dfs = [get_eval_df(dataset)['df'] for dataset in datasets_list]\n",
    "    combined_eval_df = pd.concat(eval_dfs)\n",
    "    full_slides_condition = get_full_slides_condition(combined_eval_df)\n",
    "    print(f\"full_slides_condition.mean() {full_slides_condition.mean()}\")\n",
    "    mean_agg_df = get_agg_df_per_dataset(combined_eval_df, full_slides_condition, 'mean')\n",
    "    std_agg_df = get_agg_df_per_dataset(combined_eval_df, full_slides_condition, 'std')\n",
    "    return mean_agg_df, std_agg_df\n",
    "\n",
    "mean_tcga_lung_df, std_tcga_lung_df = get_mean_and_std_dfs_from_list(['TCGA-lung'])\n",
    "mean_tcia_cptac_df, std_tcia_cptac_df = get_mean_and_std_dfs_from_list(['TCIA-CPTAC'])\n",
    "mean_ouh_df, std_ouh_df = get_mean_and_std_dfs_from_list([dataset for dataset in all_datasets if dataset.startswith('ouh')])\n",
    "mean_dart_df, std_dart_df = get_mean_and_std_dfs_from_list([dataset for dataset in all_datasets if dataset.startswith('DART')])\n",
    "mean_camelyon16_df, std_camelyon16_df = get_mean_and_std_dfs_from_list(['CAMELYON16'])\n",
    "\n",
    "mean_tcga_lung_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parallel_coordinates(mean_df: pd.DataFrame, metric_columns: list[str],title: str='Clustering Metrics', baseline=0.5):\n",
    "    plt.figure(figsize=(7.5, 3))\n",
    "    parallel_coordinates(\n",
    "        mean_df,\n",
    "        'model',\n",
    "        cols=metric_columns,\n",
    "        color=plt.cm.Set2.colors,\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(\n",
    "        # bbox_to_anchor=(0.01, 0.01, 1.05, 1.05),\n",
    "        loc='lower right',\n",
    "        ncol=3, borderaxespad=0.)\n",
    "    plt.ylim(baseline, 1.0)\n",
    "    plt.savefig(f\"./figures/parallel_coordinates_{title.replace(' ', '_')}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# very good\n",
    "plot_parallel_coordinates(\n",
    "    mean_ouh_df,\n",
    "    get_eval_df_from_list([dataset for dataset in all_datasets if dataset.startswith('ouh')])['metric_columns'],\n",
    "    'OUH Lung Clustering Metrics',\n",
    "    baseline=0.6,\n",
    ")\n",
    "plot_parallel_coordinates(\n",
    "    mean_dart_df,\n",
    "    get_eval_df_from_list([dataset for dataset in all_datasets if dataset.startswith('DART')])['metric_columns'],\n",
    "    'DART Lung Clustering Metrics',\n",
    "    baseline=0.6,\n",
    ")\n",
    "# ok\n",
    "plot_parallel_coordinates(mean_tcga_lung_df, get_eval_df('TCGA-lung')['metric_columns'], 'TCGA Lung Clustering Metrics', baseline=0.5)\n",
    "# pretty bad\n",
    "plot_parallel_coordinates(mean_tcia_cptac_df, get_eval_df('TCIA-CPTAC')['metric_columns'], 'TCIA-CPTAC Lung Clustering Metrics', baseline=0.1)\n",
    "plot_parallel_coordinates(mean_camelyon16_df, get_eval_df('CAMELYON16')['metric_columns'], 'CAMELYON16 Clustering Metrics', baseline=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_mean_df, radar_std_df = get_mean_and_std_dfs_per_dataset_from_list(all_datasets)\n",
    "# drop rows that have (model=\"ResNet18...\" and img_norm=\"imagenet\") # done in get_eval_df()\n",
    "# remove_condition = (mean_df['model'].str.startswith('ResNet18')) & (mean_df['img_norm'] == 'imagenet') #\n",
    "# radar_mean_df = mean_df[~remove_condition].drop(columns=['img_norm'])\n",
    "# radar_std_df = std_df[~remove_condition].drop(columns=['img_norm'])\n",
    "# subset columns\n",
    "subset_columns = ['dataset', 'model', OPTIMIZING_METRIC]\n",
    "radar_mean_df = radar_mean_df[subset_columns]\n",
    "radar_std_df = radar_std_df[subset_columns]\n",
    "# if model name starts with \"ResNet18\", change it to \"ResNet18-SimCLR\"\n",
    "radar_mean_df['model'] = radar_mean_df['model'].apply(lambda x: 'ResNet18-SimCLR' if x.startswith('ResNet18') else x)\n",
    "radar_std_df['model'] = radar_std_df['model'].apply(lambda x: 'ResNet18-SimCLR' if x.startswith('ResNet18') else x)\n",
    "radar_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_radar_chart_complete_data(radar_mean_df, optimizing_metric, baseline_value):\n",
    "    radar_models = radar_mean_df['model'].unique()\n",
    "    print(radar_models)\n",
    "\n",
    "    radar_datasets = radar_mean_df['dataset'].unique()\n",
    "    print(radar_datasets)\n",
    "\n",
    "    df_list = [radar_mean_df[radar_mean_df['dataset'] == dataset] for dataset in radar_datasets]\n",
    "\n",
    "    # Prepare radar plot\n",
    "    num_vars = len(radar_datasets)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Close the plot\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5), subplot_kw=dict(polar=True))\n",
    "\n",
    "    # Plot baseline values\n",
    "    baseline_values = [baseline_value] * num_vars\n",
    "    baseline_values += baseline_values[:1]  # Close the line\n",
    "\n",
    "    # Loop through models to plot their performance\n",
    "    for model in radar_models:\n",
    "        model_values = [\n",
    "            df[df['model'] == model][optimizing_metric].values[0]\n",
    "            for df in df_list\n",
    "        ]\n",
    "        model_values += model_values[:1]  # Close the line\n",
    "        ax.plot(angles, model_values, label=model, linewidth=2)\n",
    "        ax.fill(angles, model_values, alpha=0.1)\n",
    "\n",
    "    # Add labels and legend\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(radar_datasets)\n",
    "    ax.set_title(optimizing_metric, size=20, pad=20)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.4, 1.2))\n",
    "\n",
    "    # Set the y-axis limit to start from the baseline value\n",
    "    ax.set_ylim(baseline_value, 1)\n",
    "\n",
    "    plt.savefig(f\"./figures/radar_chart_baseline_{optimizing_metric.replace(' ', '_')}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "baseline_value = 0.3  # Replace with your actual baseline value\n",
    "plot_radar_chart_complete_data(radar_mean_df, OPTIMIZING_METRIC, baseline_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox-simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
